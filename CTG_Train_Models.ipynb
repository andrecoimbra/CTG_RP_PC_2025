{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrecoimbra/CTG_RP_PC_2025/blob/main/CTG_Train_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixM0WA8D2zyB"
      },
      "source": [
        "# Config Colab Instance\n",
        "\n",
        "Install packages and download libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2rzrydi2w3m"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpnO1Izd9u2N"
      },
      "source": [
        "## Download config file from GitHub Repo\n",
        "\n",
        "Include any default source files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL84CKlr15Tf"
      },
      "outputs": [],
      "source": [
        "! rm config_local.py\n",
        "! wget https://raw.githubusercontent.com/andrecoimbra/CTG_RP_PC_2025/main/src/config_local.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDZ52Pjv15Z9"
      },
      "outputs": [],
      "source": [
        "from config_local import get_default_github_src_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoyuvq09_gy"
      },
      "source": [
        "### Download other specified files from src folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VSjaeZs4sa6"
      },
      "outputs": [],
      "source": [
        "get_default_github_src_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-wo0GH44slj"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foMmePwK43q5"
      },
      "outputs": [],
      "source": [
        "# test code\n",
        "import test as test\n",
        "test.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO-X4lflMl1m"
      },
      "source": [
        "## Install Packages Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neJUrW_kMLYM"
      },
      "outputs": [],
      "source": [
        "! pip install wfdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYCbBmvJMRjG"
      },
      "outputs": [],
      "source": [
        "! pip install pyts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D_y8-VFMrpu"
      },
      "source": [
        "## Download CTU-UHB Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7Hphx0ULlKj"
      },
      "outputs": [],
      "source": [
        "#!rsync -Cavz physionet.org::ctu-uhb-ctgdb  /content/ctu-uhb-ctgdb\n",
        "# !wget -r -N -c -np -nv -P /content/ctu-uhb-ctgdb https://physionet.org/files/ctu-uhb-ctgdb/1.0.0/\n",
        "!gdown 1h_qlULLpSR9fAJvzeE1Zkq2C2aIuB-N9\n",
        "!unzip \"/content/ctu-uhb-ctgdb.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7RmaSb1ntDR"
      },
      "outputs": [],
      "source": [
        "# !mv /content/ctu-uhb-ctgdb/physionet.org/files/ctu-uhb-ctgdb/1.0.0/* /content/ctu-uhb-ctgdb\n",
        "# !rm -r /content/ctu-uhb-ctgdb/physionet.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdV-UfCWAbe1"
      },
      "source": [
        "# Generate Recurrence Plots and Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "hAtjRNhWoUky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c75SbCPBAbe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import gc #garbage collector\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from fastai.vision.all import *\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "from config_local import RECORDINGS_DIR, THRESHOLD_PH\n",
        "from ctg_utils import balance_files\n",
        "\n",
        "from compute_metadata import generate_list, save_label_file\n",
        "from generate_recurrence_images import generate_rp_images_segment, gen_recurrence_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balance Dataset"
      ],
      "metadata": {
        "id": "s2iiLMoNTWJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RECORDINGS_DIR, THRESHOLD_PH"
      ],
      "metadata": {
        "id": "uH8N-7KKzF83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "\n",
        "balance_files(RECORDINGS_DIR, threshold=THRESHOLD_PH, verbose=True)"
      ],
      "metadata": {
        "id": "Ih8VTynhxEF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ai9ZTafGiL2"
      },
      "source": [
        "## Config\n",
        "Configure Recurrence Plot Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzy4_PXLtx09"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "\n",
        "POLICY='late_valid' # 'best_quality', 'early_valid', 'late_valid'\n",
        "SEG_LENGTH = 15\n",
        "\n",
        "IMAGES_DIR = '/content/images_rp_{}_{}min'.format(POLICY, SEG_LENGTH)\n",
        "print(IMAGES_DIR)\n",
        "\n",
        "CMAP=\"binary\" # \"plasma\"\n",
        "\n",
        "rp_params = gen_recurrence_params(dimensions=[2], time_delays=[1], percentages=[1, 3, 10], use_clip_vals=[False])\n",
        "# rp_params = gen_recurrence_params(dimensions=[2, 3], time_delays=list(range(1,11)), percentages=list(range(1,11)), use_clip_vals=[False])\n",
        "len(rp_params), rp_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO7NNv_NAbfH"
      },
      "outputs": [],
      "source": [
        "tfms=[]\n",
        "size=224\n",
        "bs=64\n",
        "workers=4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N__cHZs7L5LG"
      },
      "source": [
        "## Generate Recurrence Plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -R '{IMAGES_DIR}'"
      ],
      "metadata": {
        "id": "AujU8Qo07NVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making sure images are generated correctly"
      ],
      "metadata": {
        "id": "EJK8Vq45ozHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_rp_images_segment(RECORDINGS_DIR, images_dir=IMAGES_DIR, rp_params=rp_params,\n",
        "                           policy=POLICY, show_signal=False, show_image=True, verbose=True, cmap=CMAP,\n",
        "                           limit=5, max_seg_min=SEG_LENGTH, n_dec=4)"
      ],
      "metadata": {
        "id": "sP9DRsPthzpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the images from all randomly selected samples (balanced dataset)"
      ],
      "metadata": {
        "id": "T3nyQwfwpLEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAYUz9f0MTPu"
      },
      "outputs": [],
      "source": [
        "generate_rp_images_segment(RECORDINGS_DIR, images_dir=IMAGES_DIR, rp_params=rp_params,\n",
        "                           policy=POLICY, show_signal=False, show_image=False, verbose=False,\n",
        "                           cmap=CMAP, max_seg_min=SEG_LENGTH, n_dec=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the amount of images in the folder"
      ],
      "metadata": {
        "id": "FY3lHSGxT2cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find '{IMAGES_DIR}' -type f -name '*.tif' | wc -l"
      ],
      "metadata": {
        "id": "WKiMeVNAwQU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the size of the image folder"
      ],
      "metadata": {
        "id": "CqMHoxEAT_A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! du -sh '{IMAGES_DIR}'"
      ],
      "metadata": {
        "id": "jho2_e5Gxmzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXcz4vuVAbfA"
      },
      "source": [
        "## Generate Train and Test Label Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lEivw5PAbfB"
      },
      "outputs": [],
      "source": [
        "random.seed(1234)\n",
        "\n",
        "recordings, outcomes, results = generate_list(image_dir=IMAGES_DIR, image_file='rp_images_index.json',\n",
        "                                              thresh=THRESHOLD_PH, key='pH', verbose=False)\n",
        "\n",
        "save_label_file(results, image_dir=IMAGES_DIR, csv_file='labels.csv')\n",
        "\n",
        "# Checking the first 5 entries\n",
        "recordings[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure there’s no data leakage by considering the prefixes"
      ],
      "metadata": {
        "id": "NdvpBICKRc6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the labels file\n",
        "df = pd.read_csv(f'{IMAGES_DIR}/labels.csv')\n",
        "\n",
        "# Extract the prefix before the first '_'\n",
        "df[\"prefix\"] = df[\"fname\"].apply(lambda x: x.split(\"_\")[0])\n",
        "\n",
        "# Get the unique prefixes\n",
        "unique_prefixes = df[\"prefix\"].unique()\n",
        "\n",
        "# Create the folds ensuring that the same prefix stays in the same set\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds = {}\n",
        "\n",
        "# Distribute the prefixes across the folds\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_prefixes)):\n",
        "    train_prefixes = unique_prefixes[train_idx]\n",
        "    test_prefixes = unique_prefixes[test_idx]\n",
        "\n",
        "    # Select the samples corresponding to the chosen prefixes\n",
        "    train_set = df[df[\"prefix\"].isin(train_prefixes)]\n",
        "    test_set = df[df[\"prefix\"].isin(test_prefixes)]\n",
        "\n",
        "    folds[fold] = {\"train\": train_set, \"test\": test_set}\n",
        "\n",
        "# # Display the size of each set in the first fold as an example\n",
        "folds[0][\"train\"].shape, folds[0][\"test\"].shape, folds[0][\"train\"].head(), folds[0][\"test\"].head()"
      ],
      "metadata": {
        "id": "2JtSMyyuVjaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display the training parameters\n",
        "def print_training_params(learn):\n",
        "    print(\"Training parameters in Fastai:\\n\")\n",
        "    print(f\"- Optimization function: {learn.opt_func.__name__}\")\n",
        "    print(f\"- Learning rate: {learn.lr}\")\n",
        "    print(f\"- Loss function: {learn.loss_func}\\n\")"
      ],
      "metadata": {
        "id": "jEiNrVN2AUQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolutional Neural Network [CNN] - RP"
      ],
      "metadata": {
        "id": "6H868W3kpY4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "9HlAmglqhki6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Original Model (64x64)"
      ],
      "metadata": {
        "id": "Wb9U2_o9W_Hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model described in the article \"Computer-Aided Diagnosis System of Fetal Hypoxia Incorporating Recurrence Plot With Convolutional Neural Network\""
      ],
      "metadata": {
        "id": "YRi7QXEVV5LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelArticle(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelArticle, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 5),                 # 60 × 60 × 8\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(3, stride=2),          # 29 × 29 × 8\n",
        "            nn.Conv2d(8, 8, 5),                 # 25 × 25 × 8\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(3, stride=2),          # 12 × 12 × 8\n",
        "            nn.Flatten(),                       # 1152\n",
        "            nn.Linear(1152, 144),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.8),\n",
        "            nn.Linear(144, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "def get_dataloaders(fold, path_to_images, bs=32):\n",
        "    train_df = folds[fold][\"train\"]\n",
        "    dls = ImageDataLoaders.from_df(\n",
        "        train_df,\n",
        "        path=path_to_images,\n",
        "        fn_col='fname',\n",
        "        label_col='label',\n",
        "        valid_pct=0.2,\n",
        "        item_tfms=Resize(64),\n",
        "        bs=bs\n",
        "    )\n",
        "    return dls"
      ],
      "metadata": {
        "id": "kbKI7maqZGbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Our Model (224x224)"
      ],
      "metadata": {
        "id": "msyOQMCuw_8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted input to 224x224, since is a common dimension for pretrained models"
      ],
      "metadata": {
        "id": "UaNi9DIccSoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(14 * 14 * 128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "def get_dataloaders(fold, path_to_images, bs=32):\n",
        "    train_df = folds[fold][\"train\"]\n",
        "    dls = ImageDataLoaders.from_df(\n",
        "        train_df,\n",
        "        path=path_to_images,\n",
        "        fn_col='fname',\n",
        "        label_col='label',\n",
        "        valid_pct=0.2,\n",
        "        item_tfms=Resize(224),\n",
        "        bs=bs\n",
        "    )\n",
        "    return dls"
      ],
      "metadata": {
        "id": "EAxpIJJZ8_4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####RESNET18"
      ],
      "metadata": {
        "id": "7m4LBQzfjXX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.model = resnet18(pretrained=True)\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(in_features, 2)  # Ajustando para saída binária\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_dataloaders(fold, path_to_images, bs=32):\n",
        "    train_df = folds[fold][\"train\"]\n",
        "    dls = ImageDataLoaders.from_df(\n",
        "        train_df,\n",
        "        path=path_to_images,\n",
        "        fn_col='fname',\n",
        "        label_col='label',\n",
        "        valid_pct=0.2,\n",
        "        item_tfms=Resize(224),\n",
        "        bs=bs\n",
        "    )\n",
        "    return dls"
      ],
      "metadata": {
        "id": "TyocYBHtjZMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####EfficientNet B0"
      ],
      "metadata": {
        "id": "s2qnfQWXrbrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetB0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EfficientNetB0, self).__init__()\n",
        "        self.model = models.efficientnet_b0(pretrained=True)\n",
        "        in_features = self.model.classifier[1].in_features\n",
        "        self.model.classifier[1] = nn.Linear(in_features, 2)  # Saída binária\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_dataloaders(fold, path_to_images, bs=32):\n",
        "    train_df = folds[fold][\"train\"]\n",
        "    dls = ImageDataLoaders.from_df(\n",
        "        train_df,\n",
        "        path=path_to_images,\n",
        "        fn_col='fname',\n",
        "        label_col='label',\n",
        "        valid_pct=0.2,\n",
        "        item_tfms=Resize(224),\n",
        "        bs=bs\n",
        "    )\n",
        "    return dls\n"
      ],
      "metadata": {
        "id": "hqMwG_AMraOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing"
      ],
      "metadata": {
        "id": "b3whamiyhfLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store metrics\n",
        "metrics = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"specificity\": [], \"f1_score\": []}\n",
        "\n",
        "# Training and testing loop\n",
        "for fold in range(len(folds)):\n",
        "    dls = get_dataloaders(fold, IMAGES_DIR, bs)\n",
        "\n",
        "    # Reset the model for each fold\n",
        "    model = ModelArticle() # ModelArticle, MyModel, ResNet18, EfficientNetB0\n",
        "\n",
        "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=[accuracy])\n",
        "    learn.fine_tune(10)\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    test_df = folds[fold][\"test\"]\n",
        "    test_dl = dls.test_dl(test_df[\"fname\"].apply(lambda x: Path(IMAGES_DIR)/x))\n",
        "    preds, _ = learn.get_preds(dl=test_dl)\n",
        "\n",
        "    # Convert predictions to binary labels\n",
        "    pred_labels = preds.argmax(dim=1).cpu().numpy()\n",
        "    true_labels = test_df[\"label\"].values\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Manually calculate metrics\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    error_rate = 1 - acc\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Store metrics\n",
        "    metrics[\"accuracy\"].append(acc)\n",
        "    metrics[\"precision\"].append(precision)\n",
        "    metrics[\"recall\"].append(recall)\n",
        "    metrics[\"specificity\"].append(specificity)\n",
        "    metrics[\"f1_score\"].append(f1_score)\n",
        "\n",
        "    # Display metrics for the fold\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  Accuracy: {acc:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Sensitivity (Recall): {recall:.4f}\")\n",
        "    print(f\"  Specificity: {specificity:.4f}\")\n",
        "    print(f\"  F1-score: {f1_score:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if fold == len(folds) - 1:\n",
        "        print_training_params(learn)\n",
        "        learn.show_results(max_n=6)\n",
        "\n",
        "    # Free the model and GPU memory (if using CUDA)\n",
        "    del learn           # Delete the Learner object\n",
        "    del model         # Delete the model\n",
        "    torch.cuda.empty_cache()  # Free GPU memory, if necessary\n",
        "\n",
        "    # Garbage collect to free unreferenced objects\n",
        "    gc.collect()\n",
        "\n",
        "# Calculate average performance\n",
        "total_metrics = {key: np.mean(values) for key, values in metrics.items()}\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(\"-> AVERAGE MODEL PERFORMANCE: \\n\")\n",
        "for key, value in total_metrics.items():\n",
        "    metric_name = key.replace('_', ' ').capitalize()\n",
        "    print(f\"Avg. {metric_name}: {value:.4f}\")\n",
        "\n",
        "print('\\n1 - normal (pH >= 7.15)')\n",
        "print('0 - hypoxia (pH < 7.15)')"
      ],
      "metadata": {
        "id": "2vdg-WvDAVs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Poincaré Plot"
      ],
      "metadata": {
        "id": "Jhw15fpKbIEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from generate_poincare_images import generate_pc_images_segment"
      ],
      "metadata": {
        "id": "OpGxm2TnWyw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "\n",
        "POLICY='early_valid' # 'best_quality', 'early_valid', 'late_valid'\n",
        "SEG_LENGTH = 30\n",
        "\n",
        "CMAP=None\n",
        "\n",
        "# pc_lags = [1]\n",
        "pc_lags = list(range(1, 11)) # 10 lags\n",
        "\n",
        "\n",
        "IMAGES_DIR = '/content/images_pc_{}_{}min'.format(POLICY, SEG_LENGTH)\n",
        "print(IMAGES_DIR)"
      ],
      "metadata": {
        "id": "ZIfoLoOra_ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfms=[]\n",
        "size=224\n",
        "bs=64\n",
        "workers=4"
      ],
      "metadata": {
        "id": "y9vMNE3i8YLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making sure images are generated correctly"
      ],
      "metadata": {
        "id": "uXHCHHDeihKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_pc_images_segment(RECORDINGS_DIR, images_dir=IMAGES_DIR, pc_lags=pc_lags,\n",
        "                           policy=POLICY, show_signal=False, show_image=True, verbose=False, cmap=CMAP,\n",
        "                           limit=1, max_seg_min=SEG_LENGTH, n_dec=1)"
      ],
      "metadata": {
        "id": "25i6MbydbM0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the images from all randomly selected samples (balanced dataset)"
      ],
      "metadata": {
        "id": "JQh4iR9eihuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_pc_images_segment(RECORDINGS_DIR, images_dir=IMAGES_DIR, pc_lags=pc_lags,\n",
        "                           policy=POLICY, show_signal=False, show_image=False, verbose=False,\n",
        "                           cmap=CMAP, max_seg_min=SEG_LENGTH, n_dec=4)"
      ],
      "metadata": {
        "id": "fEqNxcHldIxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the amount of images in the folder"
      ],
      "metadata": {
        "id": "VEE_T9-JiQbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find '{IMAGES_DIR}' -type f -name '*.tif' | wc -l"
      ],
      "metadata": {
        "id": "rzQk82fnvPzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the size of the image folder"
      ],
      "metadata": {
        "id": "E3cTZQSQiRNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh '{IMAGES_DIR}'"
      ],
      "metadata": {
        "id": "iU3_e37AvSbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Train and Test Label Files"
      ],
      "metadata": {
        "id": "kPRCkdILip73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "\n",
        "recordings, outcomes, results = generate_list(image_dir=IMAGES_DIR, image_file='pc_images_index.json',\n",
        "                                              thresh=7.15, key='pH', verbose=True)\n",
        "\n",
        "save_label_file(results, image_dir=IMAGES_DIR, csv_file='labels.csv')\n",
        "\n",
        "# Checking the first 5 entries\n",
        "recordings[0:5]"
      ],
      "metadata": {
        "id": "ISvmufzudUX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the labels file\n",
        "df = pd.read_csv(f'{IMAGES_DIR}/labels.csv')\n",
        "\n",
        "# Extract the prefix before the first '_'\n",
        "df[\"prefix\"] = df[\"fname\"].apply(lambda x: x.split(\"_\")[0])\n",
        "\n",
        "# Get the unique prefixes\n",
        "unique_prefixes = df[\"prefix\"].unique()\n",
        "\n",
        "# Create the folds ensuring that the same prefix stays in the same set\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "folds = {}\n",
        "\n",
        "# Distribute the prefixes across the folds\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(unique_prefixes)):\n",
        "    train_prefixes = unique_prefixes[train_idx]\n",
        "    test_prefixes = unique_prefixes[test_idx]\n",
        "\n",
        "    # Select the samples corresponding to the chosen prefixes\n",
        "    train_set = df[df[\"prefix\"].isin(train_prefixes)]\n",
        "    test_set = df[df[\"prefix\"].isin(test_prefixes)]\n",
        "\n",
        "    folds[fold] = {\"train\": train_set, \"test\": test_set}\n",
        "\n",
        "# # Display the size of each set in the first fold as an example\n",
        "folds[0][\"train\"].shape, folds[0][\"test\"].shape, folds[0][\"train\"].head(), folds[0][\"test\"].head()"
      ],
      "metadata": {
        "id": "8tQeUFgPdaiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolutional Neural Network [CNN] - PC"
      ],
      "metadata": {
        "id": "YimgOS25jRcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Model (224x224)"
      ],
      "metadata": {
        "id": "NhIj_8BPjaxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(14 * 14 * 128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_dataloaders(fold, path_to_images, bs=32):\n",
        "    \"\"\"Cria ImageDataLoaders a partir do fold especificado.\"\"\"\n",
        "    train_df = folds[fold][\"train\"]\n",
        "    dls = ImageDataLoaders.from_df(\n",
        "        train_df,\n",
        "        path=path_to_images,\n",
        "        fn_col='fname',\n",
        "        label_col='label',\n",
        "        valid_pct=0.2,\n",
        "        item_tfms=Resize(224),\n",
        "        bs=bs\n",
        "    )\n",
        "    return dls"
      ],
      "metadata": {
        "id": "nLTpKDEIUPqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing"
      ],
      "metadata": {
        "id": "w9VZlLMOjt8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store metrics\n",
        "metrics = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"specificity\": [], \"f1_score\": []}\n",
        "\n",
        "# Training and testing loop\n",
        "for fold in range(len(folds)):\n",
        "    dls = get_dataloaders(fold, IMAGES_DIR, bs)\n",
        "\n",
        "    # Reset the model for each fold\n",
        "    model = MyModel() # ModelArticle, MyModel, ResNet18, EfficientNetB0\n",
        "\n",
        "    learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=[accuracy])\n",
        "    learn.fine_tune(3)\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    test_df = folds[fold][\"test\"]\n",
        "    test_dl = dls.test_dl(test_df[\"fname\"].apply(lambda x: Path(IMAGES_DIR)/x))\n",
        "    preds, _ = learn.get_preds(dl=test_dl)\n",
        "\n",
        "    # Convert predictions to binary labels\n",
        "    pred_labels = preds.argmax(dim=1).cpu().numpy()\n",
        "    true_labels = test_df[\"label\"].values\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Manually calculate metrics\n",
        "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
        "    error_rate = 1 - acc\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Store metrics\n",
        "    metrics[\"accuracy\"].append(acc)\n",
        "    metrics[\"precision\"].append(precision)\n",
        "    metrics[\"recall\"].append(recall)\n",
        "    metrics[\"specificity\"].append(specificity)\n",
        "    metrics[\"f1_score\"].append(f1_score)\n",
        "\n",
        "    # Display metrics for the fold\n",
        "    print(f\"Fold {fold}:\")\n",
        "    print(f\"  Accuracy: {acc:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Sensitivity (Recall): {recall:.4f}\")\n",
        "    print(f\"  Specificity: {specificity:.4f}\")\n",
        "    print(f\"  F1-score: {f1_score:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if fold == len(folds) - 1:\n",
        "        print_training_params(learn)\n",
        "        learn.show_results(max_n=6)\n",
        "\n",
        "    # Free the model and GPU memory (if using CUDA)\n",
        "    del learn           # Delete the Learner object\n",
        "    del model         # Delete the model\n",
        "    torch.cuda.empty_cache()  # Free GPU memory, if necessary\n",
        "\n",
        "    # Garbage collect to free unreferenced objects\n",
        "    gc.collect()\n",
        "\n",
        "# Calculate average performance\n",
        "total_metrics = {key: np.mean(values) for key, values in metrics.items()}\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(\"-> AVERAGE MODEL PERFORMANCE: \\n\")\n",
        "for key, value in total_metrics.items():\n",
        "    metric_name = key.replace('_', ' ').capitalize()\n",
        "    print(f\"Avg. {metric_name}: {value:.4f}\")\n",
        "\n",
        "print('\\n1 - normal (pH >= 7.15)')\n",
        "print('0 - hypoxia (pH < 7.15)')"
      ],
      "metadata": {
        "id": "JHk9xfV-jnXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional info"
      ],
      "metadata": {
        "id": "Eo_2fKK8nhLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "QDrtqmI7nZzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai; fastai.__version__"
      ],
      "metadata": {
        "id": "NSXnVAT0narB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "msyOQMCuw_8R",
        "7m4LBQzfjXX3",
        "s2qnfQWXrbrq",
        "Eo_2fKK8nhLB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}